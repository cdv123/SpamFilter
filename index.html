<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
    <link rel="stylesheet" href="style.css" />
    <meta charset="UTF-8">
    <!-- pyscript library-->
    <script defer src="https://pyscript.net/latest/pyscript.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- d3 library-->
    <script src="https://d3js.org/d3.v6.min.js"></script>
    <title>Analysis of different methods for spam classification</title>
    <py-config>
        packages= ["numpy","matplotlib"]
        [[fetch]]
        from = "./"
        files =["word2vec.py", "simplifyDataset.py","oneHot.py","naiveBayesMethod.py","neuralNetwork.py","wordEmbedding.py"]
    </py-config>
</head>
<body>
    <h1>Spam Detection</h1>
    <label for="msg-input" id = "msg-label">Input spam (or ham) message here:</label>
    <input type="text" id = "msg-input">
    <button onclick="showX()" id = "Evaluate">Evaluate Message</button>
    <div id = "modal-results">
        <div id="my_dataviz"></div>
        <button class = "close-btn" id = "close-results">X</button>
        <div id = "results-chart"></div>
    </div> 
    <button id = "settings-btn"> Settings</button>
    <div id = "plot"> </div>
    <div id = "config">
        <button class = "close-btn" id = "close-config">X</button>
        <p class = "line">
            <p class = "model">Naive Bayes Model:</p>
            <p class = "epoch-num">Prior spam probability</p>
            <input class ="number-input" type="number" name="" value="0.50" min ="0" max = "1" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "setting">Words Used</p>
            <input class ="number-input" type="number" name="" value="1000" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <button id = "btn-naive-bayes" class = "confirm-settings">Confirm and Retrain Naive Bayes</button>
        </p>
        <p class = "line">
            <p class = "model">One-Hot Model:</p>
            <p class = "epoch-num">Vector Size:</p>
            <input class ="number-input" type="number" name="" value="100" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "epoch-num">Number of epochs:</p>
            <input class ="number-input" type="number" name="" value="20" min = "0" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "setting">Learning Rate:</p>
            <input class = "number-input" type="number" name="" value="0.003" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <button id = "btn-one-hot" class = "confirm-settings">Confirm and Retrain One-Hot</button>
        </p>
        <p class = "line">
            <p class = "model">Word2Vec Model:</p>
            <p class = "epoch-num">Number of epochs:</p>
            <input class = "number-input" type="number" name="" value="20" min = "0" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "setting">Learning Rate:</p>
            <input class = "number-input" type="number" name="" value="0.001" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "add-hidden">Add hidden layer</p>
            <input id = "checkbox-word2vec" class = "hidden-layer" type="checkbox" name="" value="">
            <p class = "hidden-nodes-num hidden-word2vec">Number of nodes in hidden layer:</p>
            <input class = "hidden-nodes hidden-word2vec" type="" name="" value="9" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <button id = "btn-word2vec" class = "confirm-settings">Confirm and Retrain Word2Vec</button>
        </p>
        <p class = "line">
            <p class = "model">Skip Gram Model</p>
            <p class = "epoch-num">Number of epochs of skip gram:</p>
            <input class = "number-input" type="number" name="" value="3" min = "0" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "setting">Learning Rate of skip gram:</p>
            <input class = "number-input" type="number" name="" value="0.0005" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "setting">Dimension of Word Embedding</p>
            <input class = "number-input" type="number" name="" value="50" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "epoch-num"> Number of epochs of classification</p>
            <input class = "number-input" type="number" name="" value="20" min = "0" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <p class = "epoch-num"> Learning Rate of classification</p>
            <input class = "number-input" type="number" name="" value="0.0004" min = "0" onkeydown="this.style.width = ((this.value.length + 1) * 9) + 'px';">
            <button id = "btn-skip-gram" class = "confirm-settings">Train Skip Gram Model</button>
        </p>
    </div>
    <button class = "close-btn" id = "close-plot">X</button>
    <py-script> 
    import numpy as np
    from word2vec import sentenceEmbedding, useEmbedding, messageEmbedding
    from oneHot import oneHotEncode,getMostCommonWords,oneHotEncode2
    from simplifyDataset import loadSMS,convertSpamToBinary,loadMessage
    from naiveBayesMethod import trainModel, analyseMsg
    from pyodide.http import open_url
    from pyodide.http import to_js
    import js
    from pyodide.ffi import create_proxy
    import matplotlib.pyplot as plt
    from neuralNetwork import NeuralNetwork
    from wordEmbedding import skip_gram_train
    trainingText = open_url("https://raw.githubusercontent.com/cdv123/SpamFilter/webversion/Dataset/SMSSpamCollection.txt")
    customEmbedding = open_url("https://raw.githubusercontent.com/cdv123/SpamFilter/webversion/Dataset/customEmbedding.txt")
    valText = open_url("https://raw.githubusercontent.com/cdv123/SpamFilter/webversion/Dataset/SMSVal.txt")
    trainingText = trainingText.read()
    valText = valText.read()
    customEmbedding = customEmbedding.read()
    trainingData,spamData = loadSMS(trainingText)
    valData,valSpam = loadSMS(valText)
    spamData = convertSpamToBinary(spamData)
    valSpam = convertSpamToBinary(valSpam)
    vector_size = 100
    embeddingDict = useEmbedding(customEmbedding)
    word2vec_model = NeuralNetwork(1)
    one_hot_model = NeuralNetwork(1)
    skip_gram_model = NeuralNetwork(1)
    wordEmbedding = {}
    wordProbHam,wordProbSpam = None,None
    mostCommonWords = None
    priorSpam = 0.5
    skipGramTrained = 1
    def oneHotTrain(trainingData,spamData,valData,valSpam,vector_size,epochs,lr,plot_bool):
        global mostCommonWords
        mostCommonWords = getMostCommonWords(trainingData,vector_size)
        oneHotTrain = list(oneHotEncode(trainingData,mostCommonWords).values())
        oneHotVal = list(oneHotEncode(valData,mostCommonWords).values())
        global one_hot_model
        one_hot_model.train_network(epochs,oneHotTrain,spamData,lr,oneHotVal,valSpam)
        if plot_bool:
            plot(one_hot_model.error,one_hot_model.error_val,epochs)
    def naiveBayesTrain(trainingData,spamData,wordNum,inputSpamPrior):
        global priorSpam
        priorSpam = inputSpamPrior
        resultArr = trainModel(trainingData,spamData,wordNum)
        global wordProbHam 
        wordProbHam= resultArr[0]
        global wordProbSpam
        wordProbSpam = resultArr[1]
    def word2vecTrain(trainingData,spamData,valData,valSpam,epochs,lr,plot_bool,layer_num,hidden_nodes_num=0):
        trainSentences = sentenceEmbedding(trainingData,spamData,embeddingDict,100)
        valSentences = sentenceEmbedding(valData,valSpam,embeddingDict,100)
        global word2vec_model
        if layer_num == 1:
            word2vec_model.train_network(epochs,trainSentences,spamData,lr,valSentences,valSpam)
        else:
            word2vec_model.train_network(epochs,trainSentences,spamData,lr,valSentences,valSpam,hidden_nodes_num)
        if plot_bool:
            plot(word2vec_model.error,word2vec_model.error_val,epochs)
    def skipGramTrain(trainingData,spamData,valData,valSpam,epochs,lr,dim,epochs2,lr2):
        global skip_gram_model
        global wordEmbedding
        global skipGramTrained
        skipGramTrained = 2
        skip_gram_model,wordEmbedding = skip_gram_train(trainingData,spamData,valData,valSpam,epochs,lr,dim,epochs2,lr2,skip_gram_model)
        plot(skip_gram_model.error,skip_gram_model.error_val,epochs2)
    def useOneHot(model,message):
        global mostCommonWords
        message = loadMessage(message)
        oneHotData = oneHotEncode2(message,mostCommonWords)
        return model.forward_pass(oneHotData)
    def useWord2Vec(model,message):
        message = loadMessage(message)
        wordVector = messageEmbedding(message,embeddingDict)
        if model.layer_num == 2:
            return model.forward_pass(wordVector)[1]
        return model.forward_pass(wordVector)   
    def useSkipGram(model,message):
        message = loadMessage(message)
        wordVector = messageEmbedding(message,wordEmbedding)
        return model.forward_pass(wordVector)
    def plt_style():
        plt.rcParams['figure.autolayout'] = True
        plt.rcParams['figure.figsize'] = [6.4, 4.8]
        plt.rcParams['font.family'] ='serif'
        plt.rcParams['font.size'] = 12
        plt.rcParams['xtick.direction'] = 'in'
        plt.rcParams['ytick.direction'] = 'in'
        plt.rcParams['axes.linewidth'] = 1.0
        plt.rcParams['errorbar.capsize'] = 6
        plt.rcParams['lines.markersize'] = 6
        plt.rcParams['lines.markerfacecolor'] = 'white'
        plt.rcParams['mathtext.fontset'] = 'cm'
    def plot(error,error_val,epochs):
        plt_style()
        fig,ax = plt.subplots()
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss')
        ax.plot(range(epochs),error, label = "Training Loss")
        ax.plot(range(epochs),error_val, label = "Validation Loss")
        fig.legend()
        display(fig,target="plot")
    naiveBayesTrain(trainingData,spamData,1000,0.5)
    oneHotTrain(trainingData,spamData,valData,valSpam,vector_size,20,0.003,False)
    word2vecTrain(trainingData,spamData,valData,valSpam,20,0.001,False,1)
    </py-script>
    <script src = "script.js"></script>
</body>
</html>