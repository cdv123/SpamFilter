#This code used https://datajenius.com/2022/03/13/a-deep-dive-into-nlp-tokenization-encoding-word-embeddings-sentence-embeddings-word2vec-bert/ as a resource, but different application

#Probality to value:
#If probability >= 50% => spam => positive value when using sigmoid function
#If probability < 50% => ham => positive value when using sigmoid function

# First implementation with One-Hot encoding

# Second implementation with Vectors using word2Vec

# Third implementation with Vectors using custom implementation

# Fourth implementation with BERTft
